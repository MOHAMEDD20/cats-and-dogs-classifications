{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' # Set the log level to keep the warnings down\n\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nimport matplotlib.pyplot as plt","metadata":{"execution":{"iopub.status.busy":"2022-05-21T09:40:01.985297Z","iopub.execute_input":"2022-05-21T09:40:01.985549Z","iopub.status.idle":"2022-05-21T09:40:07.060234Z","shell.execute_reply.started":"2022-05-21T09:40:01.985520Z","shell.execute_reply":"2022-05-21T09:40:07.059407Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# Load the training dataset\ntrain_ds = tf.keras.preprocessing.image_dataset_from_directory(\n    '../input/cat-and-dog/training_set/training_set/',\n    labels = 'inferred',\n    batch_size = 64,\n    image_size = (224,224),\n    shuffle = True,\n    seed = 82\n)","metadata":{"execution":{"iopub.status.busy":"2022-05-21T09:40:10.962475Z","iopub.execute_input":"2022-05-21T09:40:10.962751Z","iopub.status.idle":"2022-05-21T09:40:17.883644Z","shell.execute_reply.started":"2022-05-21T09:40:10.962700Z","shell.execute_reply":"2022-05-21T09:40:17.882937Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# Load the test dataset\ntest_ds = tf.keras.preprocessing.image_dataset_from_directory(\n    '../input/cat-and-dog/test_set/test_set/',\n    labels = 'inferred',\n    batch_size = 64,\n    image_size = (224,224),\n    shuffle = True,\n    seed = 82,\n)","metadata":{"execution":{"iopub.status.busy":"2022-05-21T09:47:30.902073Z","iopub.execute_input":"2022-05-21T09:47:30.902468Z","iopub.status.idle":"2022-05-21T09:47:31.344036Z","shell.execute_reply.started":"2022-05-21T09:47:30.902432Z","shell.execute_reply":"2022-05-21T09:47:31.342767Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"# Class name list generated by image_dataset_from_directory()\ntrain_ds.class_names","metadata":{"execution":{"iopub.status.busy":"2022-05-21T09:40:21.631884Z","iopub.execute_input":"2022-05-21T09:40:21.632561Z","iopub.status.idle":"2022-05-21T09:40:21.639676Z","shell.execute_reply.started":"2022-05-21T09:40:21.632523Z","shell.execute_reply":"2022-05-21T09:40:21.638510Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# Plot out a few of the images and their labels so we can see what we're working with.\nplt.figure(figsize=(10, 10))\n\nfor images, labels in train_ds.take(1):\n    for i in range(9):\n        ax = plt.subplot(3, 3, i + 1)\n        plt.imshow(images[i].numpy().astype(\"uint8\"))\n        plt.title(train_ds.class_names[labels[i]])\n        plt.axis(\"off\")\n","metadata":{"execution":{"iopub.status.busy":"2022-05-21T09:40:27.964907Z","iopub.execute_input":"2022-05-21T09:40:27.965172Z","iopub.status.idle":"2022-05-21T09:40:30.428155Z","shell.execute_reply.started":"2022-05-21T09:40:27.965142Z","shell.execute_reply":"2022-05-21T09:40:30.425794Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# Input layer\ninputs = keras.Input(shape=[224,224,3])\n\n# Add some Conv2D and BatchNorm layers\nx = layers.Conv2D(128, 3)(inputs)\nx = layers.BatchNormalization()(x)\nx = keras.activations.relu(x)\nx = layers.MaxPool2D()(x)\nx = layers.Dense(64, activation='relu')(x)\n\nx = layers.Flatten()(x)\n\n# Make a binary output layer with sigmoid activation\noutputs = layers.Dense(1, activation='sigmoid')(x)\n\n# Create the model\nmodel = keras.Model(inputs=inputs, outputs=outputs)","metadata":{"execution":{"iopub.status.busy":"2022-05-21T09:40:38.306602Z","iopub.execute_input":"2022-05-21T09:40:38.307309Z","iopub.status.idle":"2022-05-21T09:40:38.396070Z","shell.execute_reply.started":"2022-05-21T09:40:38.307264Z","shell.execute_reply":"2022-05-21T09:40:38.395341Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2022-05-21T09:40:52.391906Z","iopub.execute_input":"2022-05-21T09:40:52.392567Z","iopub.status.idle":"2022-05-21T09:40:52.402188Z","shell.execute_reply.started":"2022-05-21T09:40:52.392531Z","shell.execute_reply":"2022-05-21T09:40:52.401435Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Use BinaryCrossEntropy as a loss function since this is a binary classification problem\nloss = keras.losses.BinaryCrossentropy()\n\n# Use Adam optimizer with default learning rate\noptimizer = keras.optimizers.Adam()\n\n# The metric to monitor during training.\nmetrics = ['accuracy']","metadata":{"execution":{"iopub.status.busy":"2022-05-21T09:41:03.231257Z","iopub.execute_input":"2022-05-21T09:41:03.231745Z","iopub.status.idle":"2022-05-21T09:41:03.235840Z","shell.execute_reply.started":"2022-05-21T09:41:03.231684Z","shell.execute_reply":"2022-05-21T09:41:03.235113Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n\nmodel.fit(train_ds, epochs=10, batch_size=64, verbose=1)","metadata":{"execution":{"iopub.status.busy":"2022-05-21T09:41:05.279807Z","iopub.execute_input":"2022-05-21T09:41:05.280325Z","iopub.status.idle":"2022-05-21T09:46:29.730259Z","shell.execute_reply.started":"2022-05-21T09:41:05.280288Z","shell.execute_reply":"2022-05-21T09:46:29.729551Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"model.evaluate(test_ds, batch_size=64, verbose=2)","metadata":{"execution":{"iopub.status.busy":"2022-05-21T09:47:36.361539Z","iopub.execute_input":"2022-05-21T09:47:36.362137Z","iopub.status.idle":"2022-05-21T09:47:43.647048Z","shell.execute_reply.started":"2022-05-21T09:47:36.362102Z","shell.execute_reply":"2022-05-21T09:47:43.646260Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"The overall accuracy of 65% isn't bad for a single model with very few images, epochs .. augments .. and no cross validation. Ok, maybe it's not quite a gold medal winning solution.\nWe can make it better!","metadata":{}},{"cell_type":"markdown","source":"One method to overcome the relatively low number of images is to use transfer learning to 'transfer knowledge' to our model.\n\nThese models have been trained on millions of images and can be easily loaded using the keras.applications API.\n\nEfficientNet\nResNet\nVGG\nand many more ..\nLet's load EfficientNetB0 and use its weights as our base model, although any of the keras.applications can be used.\nOnce loaded, we'll freeze the base model's weights, so they don't get updated during training.","metadata":{}},{"cell_type":"code","source":"# Load the base model\nbase_model = tf.keras.applications.EfficientNetB0()\n\n# Freeze the existing layers\nbase_model.trainable = False","metadata":{"execution":{"iopub.status.busy":"2022-05-21T09:49:43.971407Z","iopub.execute_input":"2022-05-21T09:49:43.972174Z","iopub.status.idle":"2022-05-21T09:49:46.734178Z","shell.execute_reply.started":"2022-05-21T09:49:43.972135Z","shell.execute_reply":"2022-05-21T09:49:46.733367Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"# Copy the input layer from the pretrained model to use as our input layer\ninputs = base_model.layers[0].input\n\n# Get all base model layers except the last two\noutputs = base_model.layers[-2].output\n\n# Add our final classification (output) layer\noutputs = layers.Dense(1, activation='sigmoid')(outputs)\n\n# Create the model\nmodel2 = keras.Model(inputs=inputs, outputs=outputs)","metadata":{"execution":{"iopub.status.busy":"2022-05-21T09:50:25.721802Z","iopub.execute_input":"2022-05-21T09:50:25.722380Z","iopub.status.idle":"2022-05-21T09:50:25.752108Z","shell.execute_reply.started":"2022-05-21T09:50:25.722340Z","shell.execute_reply":"2022-05-21T09:50:25.751426Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"# Use the same loss, opt and metrics\nloss = keras.losses.BinaryCrossentropy()\noptimizer = keras.optimizers.Adam()\nmetrics = ['accuracy']","metadata":{"execution":{"iopub.status.busy":"2022-05-21T09:50:38.765284Z","iopub.execute_input":"2022-05-21T09:50:38.765549Z","iopub.status.idle":"2022-05-21T09:50:38.770222Z","shell.execute_reply.started":"2022-05-21T09:50:38.765520Z","shell.execute_reply":"2022-05-21T09:50:38.769117Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"model2.compile(optimizer=optimizer, loss=loss, metrics=metrics)\nmodel2.fit(train_ds, epochs=10, batch_size=64, verbose=1)","metadata":{"execution":{"iopub.status.busy":"2022-05-21T09:51:07.548131Z","iopub.execute_input":"2022-05-21T09:51:07.548395Z","iopub.status.idle":"2022-05-21T09:54:13.322509Z","shell.execute_reply.started":"2022-05-21T09:51:07.548364Z","shell.execute_reply":"2022-05-21T09:54:13.321762Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"model2.evaluate(test_ds, batch_size=64, verbose=1)","metadata":{"execution":{"iopub.status.busy":"2022-05-21T09:54:15.760412Z","iopub.execute_input":"2022-05-21T09:54:15.761436Z","iopub.status.idle":"2022-05-21T09:54:21.710405Z","shell.execute_reply.started":"2022-05-21T09:54:15.761393Z","shell.execute_reply":"2022-05-21T09:54:21.709553Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":"When faced with an image classification problem where training images are few, Tensorflow makes it easy to incorporate transfer learning into your solution.\nBy simplifying loading of pre-trained weights and interfacing with various architectures, we can quickly create accurate image classification models.","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}}]}